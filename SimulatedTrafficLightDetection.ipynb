{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator data generation. \n",
    "/ Annotated files from https://drive.google.com/file/d/0B-Eiyn-CUQtxdUZWMkFfQzdObUE/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import imageio\n",
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = yaml.load(open('/home/amol/Downloads/sim_data/data/sim_training_data/sim_data_annotations.yaml','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotations': [{'class': 'Yellow',\n",
       "   'x_width': 48.0,\n",
       "   'xmin': 130.24,\n",
       "   'y_height': 120.32,\n",
       "   'ymin': 288.32},\n",
       "  {'class': 'Yellow',\n",
       "   'x_width': 47.039999999999964,\n",
       "   'xmin': 377.6,\n",
       "   'y_height': 115.51999999999998,\n",
       "   'ymin': 294.72},\n",
       "  {'class': 'Yellow',\n",
       "   'x_width': 48.319999999999936,\n",
       "   'xmin': 625.6,\n",
       "   'y_height': 119.04000000000002,\n",
       "   'ymin': 299.52}],\n",
       " 'class': 'image',\n",
       " 'filename': 'sim_data_capture/left0011.jpg'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = set()\n",
    "for box in boxes:\n",
    "    for boxi in box['annotations']:\n",
    "        label_set.add(boxi['class'].encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'Green', b'Red', b'Yellow'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_bbox(box_info):\n",
    "    vec = [box_info['x_max'],box_info['x_min'],box_info['y_max'],box_info['y_min']]\n",
    "    check1 = any([(not np.isnan(i)) and (i>0) for i in vec])\n",
    "    check2 = (box_info['x_max']<=800) and (box_info['x_min']<=800) and (box_info['x_max']>=box_info['x_min'])\n",
    "    check3 = (box_info['y_max']<=600) and (box_info['y_min']<600) and (box_info['y_max']>=box_info['y_min'])\n",
    "    return check1 and check2 and check3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_box_info(boxes_dict):\n",
    "    result_box_info = []\n",
    "    labels = []\n",
    "    for box_info in boxes_dict:\n",
    "        box_info['x_min']= box_info['xmin']\n",
    "        box_info['x_max'] = box_info['x_min']+box_info['x_width']\n",
    "        box_info['y_min']= box_info['ymin']\n",
    "        box_info['y_max'] = box_info['y_min']+box_info['y_height']\n",
    "        box_info['label'] = box_info['class']\n",
    "        if validate_bbox(box_info):\n",
    "            result_box_info.append(np.array([box_info['x_max'],box_info['x_min'],box_info['y_max'],box_info['y_min']]))\n",
    "            labels.append(box_info['label'].encode())\n",
    "        else:\n",
    "            return None \n",
    "    result_box_info = np.array(result_box_info)\n",
    "    if(len(labels)==0):\n",
    "        return {'x_max':np.array([],dtype=np.float32),'x_min':np.array([],dtype=np.float32),'y_min':np.array([],dtype=np.float32),'y_max':np.array([],dtype=np.float32),'labels':labels}\n",
    "    return {'x_max':result_box_info[:,0],'x_min':result_box_info[:,1],'y_max':result_box_info[:,2],'y_min':result_box_info[:,3],'labels':labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=extract_box_info(boxes[3]['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': [b'Yellow', b'Yellow', b'Yellow'],\n",
       " 'x_max': array([174.08, 426.88, 680.32]),\n",
       " 'x_min': array([126.72, 376.32, 625.92]),\n",
       " 'y_max': array([407.36, 413.44, 418.88]),\n",
       " 'y_min': array([285.44, 291.2 , 294.72])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELMAP = dict(zip(list(label_set),range(1,1+len(label_set))))#not sure if id should start from one but just to be safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(filename,boxes):\n",
    "    \"\"\"Creates a tf.Example proto from sample cat image.\n",
    "\n",
    "    Args:\n",
    "        encoded_image_data: The jpg encoded data of the cat image.\n",
    "\n",
    "    Returns:\n",
    "        example: The created tf.Example.\n",
    "    \"\"\"\n",
    "\n",
    "    height = 600\n",
    "    width = 800\n",
    "    image_format = b'jpg'\n",
    "\n",
    "    xmins = np.array([i/width for i in boxes['x_min']])\n",
    "    xmaxs = np.array([i/width for i in boxes['x_max']])\n",
    "    ymins = np.array([i/height for i in boxes['y_min']])\n",
    "    ymaxs = np.array([i/height for i in boxes['y_max']])\n",
    "    classes_text = boxes['labels']\n",
    "    classes = [LABELMAP[i] for i in classes_text]\n",
    "    with tf.gfile.GFile(filename,'rb') as fid:\n",
    "        encoded_image_data = fid.read()\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(filename.encode()),\n",
    "      'image/source_id': dataset_util.bytes_feature(filename.encode()),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "      'image/format': dataset_util.bytes_feature(image_format),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = create_tf_example('/home/amol/Downloads/sim_data/data/sim_training_data/'+ boxes[5]['filename'],extract_box_info(boxes[5]['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': [b'Yellow', b'Yellow', b'Yellow'],\n",
       " 'x_max': array([174.08, 426.88, 680.32]),\n",
       " 'x_min': array([126.72, 376.32, 625.92]),\n",
       " 'y_max': array([407.36, 413.44, 418.88]),\n",
       " 'y_min': array([285.44, 291.2 , 294.72])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib2\n",
    "from object_detection.dataset_tools import tf_record_creation_util\n",
    "\n",
    "num_shards=2\n",
    "output_filebase='/home/amol/ObjectDetection/SimulatorData/train_'\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter\n",
    "with contextlib2.ExitStack() as tf_record_close_stack:\n",
    "    output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
    "      tf_record_close_stack, output_filebase, num_shards)\n",
    "    index = 0\n",
    "    for box_dict in boxes[0:200]:\n",
    "        boxes_per_image = extract_box_info(box_dict['annotations'])\n",
    "        if boxes_per_image:\n",
    "            path ='/home/amol/Downloads/sim_data/data/sim_training_data/'+box_dict['filename']\n",
    "            tf_example = create_tf_example(path,boxes_per_image)\n",
    "            output_shard_index = index % num_shards\n",
    "            output_tfrecords[output_shard_index].write(tf_example.SerializeToString())\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib2\n",
    "from object_detection.dataset_tools import tf_record_creation_util\n",
    "\n",
    "num_shards=2\n",
    "output_filebase='/home/amol/ObjectDetection/SimulatorData/test_'\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter\n",
    "with contextlib2.ExitStack() as tf_record_close_stack:\n",
    "    output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
    "      tf_record_close_stack, output_filebase, num_shards)\n",
    "    index = 0\n",
    "    for box_dict in boxes[200:]:\n",
    "        boxes_per_image = extract_box_info(box_dict['annotations'])\n",
    "        if boxes_per_image:\n",
    "            path ='/home/amol/Downloads/sim_data/data/sim_training_data/'+box_dict['filename']\n",
    "            tf_example = create_tf_example(path,boxes_per_image)\n",
    "            output_shard_index = index % num_shards\n",
    "            output_tfrecords[output_shard_index].write(tf_example.SerializeToString())\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/amol/ObjectDetection/SimulatorData/label_map.pbtxt','w') as fid:\n",
    "    for key in LABELMAP.keys():\n",
    "        output_string = \"item{{id:{id}\\n name:'{name}' }}\"\n",
    "        fid.write(output_string.format(id=LABELMAP[key],name=key.decode('utf-8')))\n",
    "        fid.write('\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
